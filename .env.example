# Twitch credentials
TWITCH_ACCESS_TOKEN=""
TWITCH_CLIENT_ID=""
TWITCH_NAME=""
STREAMER_CHANNEL=""

# LLM Clients
LLM_TEMPERATURE="0.7" # The creativity of your outputs.
LLM_MODEL="llama3.2" # This must match your LLM provider
SYSTEM_PROMPT_PATH="system-prompt.txt" # Only change this if you are gonna use a different path
OUTPUT_FORMAT="llm-format.json" # Only change this if you are gonna use a different format with a different path
MAX_MESSAGES_REMEMBERED="50"
TIMEOUT_MOOD_SCORE_THRESHOLD="0.3"

# Closed source (only one token required if you don't want to use Ollama)
OPENAI_TOKEN=""
COHERE_TOKEN=""

# Open source
OLLAMA_URL="http://localhost:11434"
OLLAMA_NUM_CTX="4096"
